masternod@master-node-VMware-Virtual-Platform:~$ docker stack rm sparkcluster
Removing service sparkcluster_spark-master
Removing service sparkcluster_spark-worker
Removing network sparkcluster_spark-net
masternod@master-node-VMware-Virtual-Platform:~$ docker stack deploy -c spark-swarm.yml sparkcluster
Since --detach=false was not specified, tasks will be created in the background.
In a future release, --detach=false will become the default.
Creating network sparkcluster_spark-net
Creating service sparkcluster_spark-master
Creating service sparkcluster_spark-worker
masternod@master-node-VMware-Virtual-Platform:~$ docker service ls
ID             NAME                        MODE         REPLICAS   IMAGE                  PORTS
m9h8bj31ve30   sparkcluster_spark-master   replicated   1/1        bitnami/spark:latest   *:7077->7077/tcp, *:8081->8080/tcp
zfsn78ujp43o   sparkcluster_spark-worker   replicated   2/2        bitnami/spark:latest   
masternod@master-node-VMware-Virtual-Platform:~$ nano bio_classifier.py
masternod@master-node-VMware-Virtual-Platform:~$ ls -l cleaned_bio_dataset.csv
-rw-rw-r-- 1 masternod masternod 11753 May 30 17:14 cleaned_bio_dataset.csv
masternod@master-node-VMware-Virtual-Platform:~$ docker ps
CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS     NAMES
1541ffa4ed63   bitnami/spark:latest   "/opt/bitnami/script…"   49 minutes ago   Up 49 minutes             sparkcluster_spark-worker.2.tvk3u45oyc32cuh5wk9irtpt6
masternod@master-node-VMware-Virtual-Platform:~$ docker cp bio_classifier.py <container_id>:/opt
bash: container_id: No such file or directory
masternod@master-node-VMware-Virtual-Platform:~$ ^C
masternod@master-node-VMware-Virtual-Platform:~$ docker ps -a
CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS     NAMES
1541ffa4ed63   bitnami/spark:latest   "/opt/bitnami/script…"   51 minutes ago   Up 51 minutes             sparkcluster_spark-worker.2.tvk3u45oyc32cuh5wk9irtpt6
masternod@master-node-VMware-Virtual-Platform:~$ docker stack rm sparkcluster
Removing service sparkcluster_spark-master
Removing service sparkcluster_spark-worker
Removing network sparkcluster_spark-net
masternod@master-node-VMware-Virtual-Platform:~$ docker stack deploy -c spark-swarm.yml sparkcluster
Since --detach=false was not specified, tasks will be created in the background.
In a future release, --detach=false will become the default.
Creating service sparkcluster_spark-master
failed to create service sparkcluster_spark-master: Error response from daemon: network sparkcluster_spark-net not found
masternod@master-node-VMware-Virtual-Platform:~$ ^C
masternod@master-node-VMware-Virtual-Platform:~$ docker network create -d overlay spark-net
ic2zg97t5o2208nkoeqwn5ssr
masternod@master-node-VMware-Virtual-Platform:~$ docker network ls
NETWORK ID     NAME              DRIVER    SCOPE
57eeca7a472e   bridge            bridge    local
b72d1bcde8c5   docker_gwbridge   bridge    local
c2341fef44f7   host              host      local
pvajwgwfhsco   ingress           overlay   swarm
e85615e7e08e   none              null      local
ic2zg97t5o22   spark-net         overlay   swarm
masternod@master-node-VMware-Virtual-Platform:~$ ^C
masternod@master-node-VMware-Virtual-Platform:~$ docker stack deploy -c spark-swarm.yml sparkcluster
Since --detach=false was not specified, tasks will be created in the background.
In a future release, --detach=false will become the default.
Creating network sparkcluster_spark-net
Creating service sparkcluster_spark-master
Creating service sparkcluster_spark-worker
masternod@master-node-VMware-Virtual-Platform:~$ docker ps -a
CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS     NAMES
fbaedb8427cf   bitnami/spark:latest   "/opt/bitnami/script…"   20 seconds ago   Up 19 seconds             sparkcluster_spark-worker.1.nml4og4j8kjxahs36dpengsva
masternod@master-node-VMware-Virtual-Platform:~$ docker service ps sparkcluster_spark-master
ID             NAME                          IMAGE                  NODE                              DESIRED STATE   CURRENT STATE                ERROR     PORTS
50tfhslxvsoy   sparkcluster_spark-master.1   bitnami/spark:latest   worker1-VMware-Virtual-Platform   Running         Running about a minute ago             
masternod@master-node-VMware-Virtual-Platform:~$ docker node ls
ID                            HOSTNAME                              STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION
ub4lzq3vchev7zsh60gl89e7e *   master-node-VMware-Virtual-Platform   Ready     Active         Leader           28.1.1
g5kg3br3bs03ailko4crc2f1o     worker1-VMware-Virtual-Platform       Ready     Active                          28.1.1
lxtudxsqvni8r0fprpl2mw9l0     worker2-VMware-Virtual-Platform       Ready     Active                          28.1.1
masternod@master-node-VMware-Virtual-Platform:~$ nano spark-swarm.yml
masternod@master-node-VMware-Virtual-Platform:~$ docker stack rm sparkcluster
Removing service sparkcluster_spark-master
Removing service sparkcluster_spark-worker
Removing network sparkcluster_spark-net
masternod@master-node-VMware-Virtual-Platform:~$ docker stack deploy -c spark-swarm.yml sparkcluster
Since --detach=false was not specified, tasks will be created in the background.
In a future release, --detach=false will become the default.
Creating service sparkcluster_spark-worker
failed to create service sparkcluster_spark-worker: Error response from daemon: network sparkcluster_spark-net not found
masternod@master-node-VMware-Virtual-Platform:~$ docker stack deploy -c spark-swarm.yml sparkcluster
Since --detach=false was not specified, tasks will be created in the background.
In a future release, --detach=false will become the default.
Creating network sparkcluster_spark-net
Creating service sparkcluster_spark-master
Creating service sparkcluster_spark-worker
masternod@master-node-VMware-Virtual-Platform:~$ docker service ps sparkcluster_spark-master
ID             NAME                          IMAGE                  NODE                                  DESIRED STATE   CURRENT STATE           ERROR     PORTS
jt06h7e3t0ea   sparkcluster_spark-master.1   bitnami/spark:latest   master-node-VMware-Virtual-Platform   Running         Running 7 seconds ago             
masternod@master-node-VMware-Virtual-Platform:~$ docker ps
CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS     NAMES
b6e91231c573   bitnami/spark:latest   "/opt/bitnami/script…"   40 seconds ago   Up 39 seconds             sparkcluster_spark-master.1.jt06h7e3t0eaxo52mqivmqang
masternod@master-node-VMware-Virtual-Platform:~$ ^C
masternod@master-node-VMware-Virtual-Platform:~$ docker cp bio_classifier.py b6e91231c573:/opt
Successfully copied 3.07kB to b6e91231c573:/opt
masternod@master-node-VMware-Virtual-Platform:~$ docker cp cleaned_bio_dataset.csv b6e91231c573:/opt
Successfully copied 13.3kB to b6e91231c573:/opt
masternod@master-node-VMware-Virtual-Platform:~$ docker exec -it b6e91231c573 bash
I have no name!@b6e91231c573:/opt/bitnami/spark$ 
I have no name!@b6e91231c573:/opt/bitnami/spark$ cd /opt
I have no name!@b6e91231c573:/opt$ cd /opt
I have no name!@b6e91231c573:/opt$ spark-submit --master spark://spark-master:7077 bio_classifier.py
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:137)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1274)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1381)
	at org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:182)
	at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:339)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:969)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:199)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:222)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1125)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1134)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
I have no name!@b6e91231c573:/opt$ export HOME=/tmp
I have no name!@b6e91231c573:/opt$ spark-submit --master spark://spark-master:7077 bio_classifier.py
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:137)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1274)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1381)
	at org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:182)
	at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:339)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:969)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:199)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:222)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1125)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1134)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
I have no name!@b6e91231c573:/opt$ HOME=/tmp spark-submit --master spark://spark-master:7077 bio_classifier.py
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:137)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1274)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1381)
	at org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:182)
	at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:339)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:969)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:199)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:222)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1125)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1134)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
I have no name!@b6e91231c573:/opt$ mkdir -p /tmp/.ivy2/local
I have no name!@b6e91231c573:/opt$ export HOME=/tmp
I have no name!@b6e91231c573:/opt$ spark-submit --master spark://spark-master:7077 bio_classifier.py
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:137)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1274)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1381)
	at org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:182)
	at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:339)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:969)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:199)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:222)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1125)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1134)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
I have no name!@b6e91231c573:/opt$ exit
exit
masternod@master-node-VMware-Virtual-Platform:~$ docker exec -it --user root b6e91231c573 bash
root@b6e91231c573:/opt/bitnami/spark# spark-submit --master spark://spark-master:7077 bio_classifier.py
python3: can't open file '/opt/bitnami/spark/bio_classifier.py': [Errno 2] No such file or directory
25/05/31 19:05:36 INFO ShutdownHookManager: Shutdown hook called
25/05/31 19:05:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-caefbf13-d347-498c-98f6-4d580cc0b02c
root@b6e91231c573:/opt/bitnami/spark# ls /opt
bio_classifier.py  bitnami  cleaned_bio_dataset.csv
root@b6e91231c573:/opt/bitnami/spark# cd /opt
root@b6e91231c573:/opt# spark-submit --master spark://spark-master:7077 bio_classifier.py
Traceback (most recent call last):
  File "/opt/bio_classifier.py", line 2, in <module>
    from pyspark.ml.feature import StringIndexer, VectorAssembler
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/ml/__init__.py", line 22, in <module>
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/ml/base.py", line 40, in <module>
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/ml/param/__init__.py", line 32, in <module>
ModuleNotFoundError: No module named 'numpy'
25/05/31 19:07:52 INFO ShutdownHookManager: Shutdown hook called
25/05/31 19:07:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-3ab427d7-ce11-4760-b447-b7d6aed11015
root@b6e91231c573:/opt# pip install numpy
Collecting numpy
  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)
Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.5/16.5 MB 1.2 MB/s eta 0:00:00
Installing collected packages: numpy
Successfully installed numpy-2.2.6
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
root@b6e91231c573:/opt# spark-submit --master spark://spark-master:7077 bio_classifier.py
25/05/31 19:09:54 INFO SparkContext: Running Spark version 3.5.6
25/05/31 19:09:54 INFO SparkContext: OS info Linux, 6.11.0-26-generic, amd64
25/05/31 19:09:54 INFO SparkContext: Java version 17.0.15
25/05/31 19:09:54 INFO ResourceUtils: ==============================================================
25/05/31 19:09:54 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/31 19:09:54 INFO ResourceUtils: ==============================================================
25/05/31 19:09:54 INFO SparkContext: Submitted application: BioClassifier
25/05/31 19:09:54 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/31 19:09:54 INFO ResourceProfile: Limiting resource is cpu
25/05/31 19:09:54 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/31 19:09:54 INFO SecurityManager: Changing view acls to: root,spark
25/05/31 19:09:54 INFO SecurityManager: Changing modify acls to: root,spark
25/05/31 19:09:54 INFO SecurityManager: Changing view acls groups to: 
25/05/31 19:09:54 INFO SecurityManager: Changing modify acls groups to: 
25/05/31 19:09:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
25/05/31 19:09:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/31 19:09:56 INFO Utils: Successfully started service 'sparkDriver' on port 40707.
25/05/31 19:09:56 INFO SparkEnv: Registering MapOutputTracker
25/05/31 19:09:56 INFO SparkEnv: Registering BlockManagerMaster
25/05/31 19:09:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/31 19:09:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/31 19:09:56 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/31 19:09:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d446a9bd-7c88-4143-871b-cc2adc185a46
25/05/31 19:09:56 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
25/05/31 19:09:57 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/31 19:09:57 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/05/31 19:09:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/31 19:09:58 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/05/31 19:09:58 INFO TransportClientFactory: Successfully created connection to spark-master/10.0.2.2:7077 after 73 ms (0 ms spent in bootstraps)
25/05/31 19:09:59 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250531190959-0000
25/05/31 19:09:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41687.
25/05/31 19:09:59 INFO NettyBlockTransferService: Server created on b6e91231c573:41687
25/05/31 19:09:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/31 19:09:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250531190959-0000/0 on worker-20250531185223-10.0.2.7-45225 (10.0.2.7:45225) with 2 core(s)
25/05/31 19:09:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20250531190959-0000/0 on hostPort 10.0.2.7:45225 with 2 core(s), 1024.0 MiB RAM
25/05/31 19:09:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250531190959-0000/1 on worker-20250531185223-10.0.2.6-33679 (10.0.2.6:33679) with 2 core(s)
25/05/31 19:09:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20250531190959-0000/1 on hostPort 10.0.2.6:33679 with 2 core(s), 1024.0 MiB RAM
25/05/31 19:09:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b6e91231c573, 41687, None)
25/05/31 19:09:59 INFO BlockManagerMasterEndpoint: Registering block manager b6e91231c573:41687 with 434.4 MiB RAM, BlockManagerId(driver, b6e91231c573, 41687, None)
25/05/31 19:09:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b6e91231c573, 41687, None)
25/05/31 19:09:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b6e91231c573, 41687, None)
25/05/31 19:09:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250531190959-0000/0 is now RUNNING
25/05/31 19:10:00 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250531190959-0000/1 is now RUNNING
25/05/31 19:10:00 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/05/31 19:10:01 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/05/31 19:10:01 INFO SharedState: Warehouse path is 'file:/opt/spark-warehouse'.
25/05/31 19:10:06 INFO InMemoryFileIndex: It took 227 ms to list leaf files for 1 paths.
25/05/31 19:10:07 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/05/31 19:10:12 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.7:50920) with ID 0,  ResourceProfileId 0
25/05/31 19:10:12 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.7:41659 with 434.4 MiB RAM, BlockManagerId(0, 10.0.2.7, 41659, None)
25/05/31 19:10:13 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.6:40008) with ID 1,  ResourceProfileId 0
25/05/31 19:10:13 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.6:42667 with 434.4 MiB RAM, BlockManagerId(1, 10.0.2.6, 42667, None)
25/05/31 19:10:15 INFO FileSourceStrategy: Pushed Filters: 
25/05/31 19:10:15 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/05/31 19:10:16 INFO CodeGenerator: Code generated in 467.978195 ms
25/05/31 19:10:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.6 KiB, free 434.2 MiB)
25/05/31 19:10:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 434.2 MiB)
25/05/31 19:10:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b6e91231c573:41687 (size: 34.3 KiB, free: 434.4 MiB)
25/05/31 19:10:17 INFO SparkContext: Created broadcast 0 from csv at <unknown>:0
25/05/31 19:10:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/31 19:10:17 INFO SparkContext: Starting job: csv at <unknown>:0
25/05/31 19:10:17 INFO DAGScheduler: Got job 0 (csv at <unknown>:0) with 1 output partitions
25/05/31 19:10:17 INFO DAGScheduler: Final stage: ResultStage 0 (csv at <unknown>:0)
25/05/31 19:10:17 INFO DAGScheduler: Parents of final stage: List()
25/05/31 19:10:17 INFO DAGScheduler: Missing parents: List()
25/05/31 19:10:17 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0), which has no missing parents
25/05/31 19:10:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 434.2 MiB)
25/05/31 19:10:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.2 MiB)
25/05/31 19:10:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b6e91231c573:41687 (size: 6.4 KiB, free: 434.4 MiB)
25/05/31 19:10:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1611
25/05/31 19:10:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/05/31 19:10:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/31 19:10:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.0.2.7, executor 0, partition 0, PROCESS_LOCAL, 9601 bytes) 
25/05/31 19:10:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.2.7:41659 (size: 6.4 KiB, free: 434.4 MiB)
25/05/31 19:10:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.7:41659 (size: 34.3 KiB, free: 434.4 MiB)
25/05/31 19:10:22 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (10.0.2.7 executor 0): org.apache.spark.SparkFileNotFoundException: File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

25/05/31 19:10:22 INFO TaskSetManager: Starting task 0.1 in stage 0.0 (TID 1) (10.0.2.6, executor 1, partition 0, PROCESS_LOCAL, 9601 bytes) 
25/05/31 19:10:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.2.6:42667 (size: 6.4 KiB, free: 434.4 MiB)
25/05/31 19:10:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.6:42667 (size: 34.3 KiB, free: 434.4 MiB)
25/05/31 19:10:28 INFO TaskSetManager: Lost task 0.1 in stage 0.0 (TID 1) on 10.0.2.6, executor 1: org.apache.spark.SparkFileNotFoundException (File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 1]
25/05/31 19:10:28 INFO TaskSetManager: Starting task 0.2 in stage 0.0 (TID 2) (10.0.2.7, executor 0, partition 0, PROCESS_LOCAL, 9601 bytes) 
25/05/31 19:10:29 INFO TaskSetManager: Lost task 0.2 in stage 0.0 (TID 2) on 10.0.2.7, executor 0: org.apache.spark.SparkFileNotFoundException (File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 2]
25/05/31 19:10:29 INFO TaskSetManager: Starting task 0.3 in stage 0.0 (TID 3) (10.0.2.6, executor 1, partition 0, PROCESS_LOCAL, 9601 bytes) 
25/05/31 19:10:29 INFO TaskSetManager: Lost task 0.3 in stage 0.0 (TID 3) on 10.0.2.6, executor 1: org.apache.spark.SparkFileNotFoundException (File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 3]
25/05/31 19:10:29 ERROR TaskSetManager: Task 0 in stage 0.0 failed 4 times; aborting job
25/05/31 19:10:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/31 19:10:29 INFO TaskSchedulerImpl: Cancelling stage 0
25/05/31 19:10:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.6 executor 1): org.apache.spark.SparkFileNotFoundException: File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
25/05/31 19:10:29 INFO DAGScheduler: ResultStage 0 (csv at <unknown>:0) failed in 11.865 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.6 executor 1): org.apache.spark.SparkFileNotFoundException: File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
25/05/31 19:10:29 INFO DAGScheduler: Job 0 failed: csv at <unknown>:0, took 12.081608 s
Traceback (most recent call last):
  File "/opt/bio_classifier.py", line 10, in <module>
    df = spark.read.csv("cleaned_bio_dataset.csv", header=True, inferSchema=True)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 740, in csv
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o27.csv.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.6 executor 1): org.apache.spark.SparkFileNotFoundException: File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2898)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2834)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2833)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2833)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1253)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1253)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1253)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3102)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3036)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3025)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:995)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4333)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3316)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3316)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3539)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.infer(CSVDataSource.scala:111)
	at org.apache.spark.sql.execution.datasources.csv.CSVDataSource.inferSchema(CSVDataSource.scala:64)
	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:62)
	at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)
	at scala.Option.orElse(Option.scala:447)
	at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:538)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.base/java.lang.reflect.Method.invoke(Unknown Source)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkFileNotFoundException: File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more

25/05/31 19:10:30 INFO SparkContext: Invoking stop() from shutdown hook
25/05/31 19:10:30 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/05/31 19:10:30 INFO SparkUI: Stopped Spark web UI at http://b6e91231c573:4040
25/05/31 19:10:30 INFO StandaloneSchedulerBackend: Shutting down all executors
25/05/31 19:10:30 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
25/05/31 19:10:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/31 19:10:30 INFO MemoryStore: MemoryStore cleared
25/05/31 19:10:30 INFO BlockManager: BlockManager stopped
25/05/31 19:10:30 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/31 19:10:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/31 19:10:30 INFO SparkContext: Successfully stopped SparkContext
25/05/31 19:10:30 INFO ShutdownHookManager: Shutdown hook called
25/05/31 19:10:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-6d74ed62-b477-4f77-aea7-b712ed71d344
25/05/31 19:10:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-6f20a68e-0c94-41e6-8b35-c80a0aa9bdb6
25/05/31 19:10:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-6f20a68e-0c94-41e6-8b35-c80a0aa9bdb6/pyspark-7997f823-5eb2-45b5-8499-c512a889c034
root@b6e91231c573:/opt# docker exec -it b6e91231c573 bash
bash: docker: command not found
root@b6e91231c573:/opt# nano bio_classifier.py
bash: nano: command not found
root@b6e91231c573:/opt# ^C
root@b6e91231c573:/opt# vi bio_classifier.py
bash: vi: command not found
root@b6e91231c573:/opt# exit
exit
masternod@master-node-VMware-Virtual-Platform:~$ nano bio_classifier.py
masternod@master-node-VMware-Virtual-Platform:~$ docker cp bio_classifier.py b6e91231c573:/opt
Successfully copied 3.07kB to b6e91231c573:/opt
masternod@master-node-VMware-Virtual-Platform:~$ docker exec -it b6e91231c573 bash
I have no name!@b6e91231c573:/opt/bitnami/spark$ cd /opt
I have no name!@b6e91231c573:/opt$ spark-submit --master spark://spark-master:7077 bio_classifier.py
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:137)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1274)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1381)
	at org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:182)
	at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:339)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:969)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:199)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:222)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1125)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1134)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
I have no name!@b6e91231c573:/opt$ exit
exit
masternod@master-node-VMware-Virtual-Platform:~$ docker cp bio_classifier.py b6e91231c573:/root/
Successfully copied 3.07kB to b6e91231c573:/root/
masternod@master-node-VMware-Virtual-Platform:~$ docker cp cleaned_bio_dataset.csv b6e91231c573:/root/
Successfully copied 13.3kB to b6e91231c573:/root/
masternod@master-node-VMware-Virtual-Platform:~$ docker exec -it b6e91231c573 bash
I have no name!@b6e91231c573:/opt/bitnami/spark$ spark-submit --master spark://spark-master:7077 bio_classifier.py
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:137)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1274)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1381)
	at org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:182)
	at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:339)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:969)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:199)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:222)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1125)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1134)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
I have no name!@b6e91231c573:/opt/bitnami/spark$ exit
exit
masternod@master-node-VMware-Virtual-Platform:~$ docker cp bio_classifier.py b6e91231c573:/root/
Successfully copied 3.07kB to b6e91231c573:/root/
masternod@master-node-VMware-Virtual-Platform:~$ docker cp cleaned_bio_dataset.csv b6e91231c573:/root/
Successfully copied 13.3kB to b6e91231c573:/root/
masternod@master-node-VMware-Virtual-Platform:~$ docker exec -it b6e91231c573 bash
I have no name!@b6e91231c573:/opt/bitnami/spark$ exit
exit
masternod@master-node-VMware-Virtual-Platform:~$ docker exec -it --user root b6e91231c573 bash
root@b6e91231c573:/opt/bitnami/spark# cd /opt
root@b6e91231c573:/opt# spark-submit --master spark://spark-master:7077 bio_classifier.py
25/05/31 19:26:26 INFO SparkContext: Running Spark version 3.5.6
25/05/31 19:26:26 INFO SparkContext: OS info Linux, 6.11.0-26-generic, amd64
25/05/31 19:26:26 INFO SparkContext: Java version 17.0.15
25/05/31 19:26:26 INFO ResourceUtils: ==============================================================
25/05/31 19:26:26 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/31 19:26:26 INFO ResourceUtils: ==============================================================
25/05/31 19:26:26 INFO SparkContext: Submitted application: BioClassifier
25/05/31 19:26:26 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/31 19:26:26 INFO ResourceProfile: Limiting resource is cpu
25/05/31 19:26:26 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/31 19:26:26 INFO SecurityManager: Changing view acls to: root,spark
25/05/31 19:26:26 INFO SecurityManager: Changing modify acls to: root,spark
25/05/31 19:26:26 INFO SecurityManager: Changing view acls groups to: 
25/05/31 19:26:26 INFO SecurityManager: Changing modify acls groups to: 
25/05/31 19:26:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
25/05/31 19:26:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/31 19:26:27 INFO Utils: Successfully started service 'sparkDriver' on port 45321.
25/05/31 19:26:27 INFO SparkEnv: Registering MapOutputTracker
25/05/31 19:26:27 INFO SparkEnv: Registering BlockManagerMaster
25/05/31 19:26:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/31 19:26:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/31 19:26:27 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/31 19:26:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9ef34cfa-a309-48ed-a563-bc2399425802
25/05/31 19:26:28 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
25/05/31 19:26:28 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/31 19:26:28 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/05/31 19:26:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/31 19:26:28 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/05/31 19:26:29 INFO TransportClientFactory: Successfully created connection to spark-master/10.0.2.2:7077 after 85 ms (0 ms spent in bootstraps)
25/05/31 19:26:29 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250531192629-0001
25/05/31 19:26:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250531192629-0001/0 on worker-20250531185223-10.0.2.7-45225 (10.0.2.7:45225) with 2 core(s)
25/05/31 19:26:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20250531192629-0001/0 on hostPort 10.0.2.7:45225 with 2 core(s), 1024.0 MiB RAM
25/05/31 19:26:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250531192629-0001/1 on worker-20250531185223-10.0.2.6-33679 (10.0.2.6:33679) with 2 core(s)
25/05/31 19:26:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20250531192629-0001/1 on hostPort 10.0.2.6:33679 with 2 core(s), 1024.0 MiB RAM
25/05/31 19:26:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38423.
25/05/31 19:26:29 INFO NettyBlockTransferService: Server created on b6e91231c573:38423
25/05/31 19:26:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/31 19:26:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b6e91231c573, 38423, None)
25/05/31 19:26:29 INFO BlockManagerMasterEndpoint: Registering block manager b6e91231c573:38423 with 434.4 MiB RAM, BlockManagerId(driver, b6e91231c573, 38423, None)
25/05/31 19:26:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b6e91231c573, 38423, None)
25/05/31 19:26:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b6e91231c573, 38423, None)
25/05/31 19:26:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250531192629-0001/1 is now RUNNING
25/05/31 19:26:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250531192629-0001/0 is now RUNNING
25/05/31 19:26:30 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/05/31 19:26:31 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/05/31 19:26:31 INFO SharedState: Warehouse path is 'file:/opt/spark-warehouse'.
25/05/31 19:26:33 INFO InMemoryFileIndex: It took 109 ms to list leaf files for 1 paths.
25/05/31 19:26:33 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/05/31 19:26:37 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.7:34752) with ID 0,  ResourceProfileId 0
25/05/31 19:26:38 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.6:52330) with ID 1,  ResourceProfileId 0
25/05/31 19:26:38 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.7:36693 with 434.4 MiB RAM, BlockManagerId(0, 10.0.2.7, 36693, None)
25/05/31 19:26:38 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.6:43201 with 434.4 MiB RAM, BlockManagerId(1, 10.0.2.6, 43201, None)
25/05/31 19:26:42 INFO FileSourceStrategy: Pushed Filters: 
25/05/31 19:26:42 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/05/31 19:26:43 INFO CodeGenerator: Code generated in 370.506598 ms
25/05/31 19:26:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.6 KiB, free 434.2 MiB)
25/05/31 19:26:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 434.2 MiB)
25/05/31 19:26:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b6e91231c573:38423 (size: 34.3 KiB, free: 434.4 MiB)
25/05/31 19:26:44 INFO SparkContext: Created broadcast 0 from csv at <unknown>:0
25/05/31 19:26:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/05/31 19:26:44 INFO SparkContext: Starting job: csv at <unknown>:0
25/05/31 19:26:44 INFO DAGScheduler: Got job 0 (csv at <unknown>:0) with 1 output partitions
25/05/31 19:26:44 INFO DAGScheduler: Final stage: ResultStage 0 (csv at <unknown>:0)
25/05/31 19:26:44 INFO DAGScheduler: Parents of final stage: List()
25/05/31 19:26:44 INFO DAGScheduler: Missing parents: List()
25/05/31 19:26:44 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0), which has no missing parents
25/05/31 19:26:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 434.2 MiB)
25/05/31 19:26:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.2 MiB)
25/05/31 19:26:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b6e91231c573:38423 (size: 6.4 KiB, free: 434.4 MiB)
25/05/31 19:26:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1611
25/05/31 19:26:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/05/31 19:26:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/31 19:26:44 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.0.2.6, executor 1, partition 0, PROCESS_LOCAL, 9601 bytes) 
25/05/31 19:26:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.2.6:43201 (size: 6.4 KiB, free: 434.4 MiB)
25/05/31 19:26:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.6:43201 (size: 34.3 KiB, free: 434.4 MiB)
25/05/31 19:26:47 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (10.0.2.6 executor 1): org.apache.spark.SparkFileNotFoundException: File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

25/05/31 19:26:48 INFO TaskSetManager: Starting task 0.1 in stage 0.0 (TID 1) (10.0.2.6, executor 1, partition 0, PROCESS_LOCAL, 9601 bytes) 
25/05/31 19:26:48 INFO TaskSetManager: Lost task 0.1 in stage 0.0 (TID 1) on 10.0.2.6, executor 1: org.apache.spark.SparkFileNotFoundException (File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 1]
25/05/31 19:26:48 INFO TaskSetManager: Starting task 0.2 in stage 0.0 (TID 2) (10.0.2.7, executor 0, partition 0, PROCESS_LOCAL, 9601 bytes) 
25/05/31 19:26:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.2.7:36693 (size: 6.4 KiB, free: 434.4 MiB)
25/05/31 19:26:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.7:36693 (size: 34.3 KiB, free: 434.4 MiB)
25/05/31 19:26:51 INFO TaskSetManager: Lost task 0.2 in stage 0.0 (TID 2) on 10.0.2.7, executor 0: org.apache.spark.SparkFileNotFoundException (File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 2]
25/05/31 19:26:51 INFO TaskSetManager: Starting task 0.3 in stage 0.0 (TID 3) (10.0.2.7, executor 0, partition 0, PROCESS_LOCAL, 9601 bytes) 
25/05/31 19:26:52 INFO TaskSetManager: Lost task 0.3 in stage 0.0 (TID 3) on 10.0.2.7, executor 0: org.apache.spark.SparkFileNotFoundException (File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 3]
25/05/31 19:26:52 ERROR TaskSetManager: Task 0 in stage 0.0 failed 4 times; aborting job
25/05/31 19:26:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/31 19:26:52 INFO TaskSchedulerImpl: Cancelling stage 0
25/05/31 19:26:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.7 executor 0): org.apache.spark.SparkFileNotFoundException: File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
25/05/31 19:26:52 INFO DAGScheduler: ResultStage 0 (csv at <unknown>:0) failed in 7.633 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.7 executor 0): org.apache.spark.SparkFileNotFoundException: File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
25/05/31 19:26:52 INFO DAGScheduler: Job 0 failed: csv at <unknown>:0, took 7.868803 s
Traceback (most recent call last):
  File "/opt/bio_classifier.py", line 10, in <module>
    df = spark.read.csv("cleaned_bio_dataset.csv", header=True, inferSchema=True)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 740, in csv
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o27.csv.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.7 executor 0): org.apache.spark.SparkFileNotFoundException: File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2898)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2834)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2833)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2833)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1253)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1253)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1253)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3102)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3036)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3025)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:995)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4333)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3316)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3316)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3539)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.infer(CSVDataSource.scala:111)
	at org.apache.spark.sql.execution.datasources.csv.CSVDataSource.inferSchema(CSVDataSource.scala:64)
	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:62)
	at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)
	at scala.Option.orElse(Option.scala:447)
	at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:538)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.base/java.lang.reflect.Method.invoke(Unknown Source)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkFileNotFoundException: File file:/opt/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more

25/05/31 19:26:52 INFO SparkContext: Invoking stop() from shutdown hook
25/05/31 19:26:52 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/05/31 19:26:52 INFO SparkUI: Stopped Spark web UI at http://b6e91231c573:4040
25/05/31 19:26:52 INFO StandaloneSchedulerBackend: Shutting down all executors
25/05/31 19:26:52 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
25/05/31 19:26:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/31 19:26:53 INFO MemoryStore: MemoryStore cleared
25/05/31 19:26:53 INFO BlockManager: BlockManager stopped
25/05/31 19:26:53 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/31 19:26:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/31 19:26:53 INFO SparkContext: Successfully stopped SparkContext
25/05/31 19:26:53 INFO ShutdownHookManager: Shutdown hook called
25/05/31 19:26:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-866e8b51-e908-4459-a6fb-37cb2bf32102/pyspark-21debfa3-4f25-42ee-a555-7bb09802f0df
25/05/31 19:26:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-866e8b51-e908-4459-a6fb-37cb2bf32102
25/05/31 19:26:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-64d7f0b9-ed27-4a2e-bbef-f8bc08b0c5f8
root@b6e91231c573:/opt# cat /root/result.txt
cat: /root/result.txt: No such file or directory
root@b6e91231c573:/opt# exit
exit
masternod@master-node-VMware-Virtual-Platform:~$ nano bio_classifier.py
masternod@master-node-VMware-Virtual-Platform:~$ docker service ls
ID             NAME                        MODE         REPLICAS   IMAGE                  PORTS
ac9dutjhx74l   sparkcluster_spark-master   replicated   1/1        bitnami/spark:latest   *:7077->7077/tcp, *:8081->8080/tcp
m7110wu0cozh   sparkcluster_spark-worker   replicated   2/2        bitnami/spark:latest   
masternod@master-node-VMware-Virtual-Platform:~$ docker ps
CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS     NAMES
b908ac1d5eb1   bitnami/spark:latest   "/opt/bitnami/script…"   15 minutes ago   Up 15 minutes             sparkcluster_spark-worker.2.2az063f6ged7wkuuuq9smbipq
5ff75d47e6db   bitnami/spark:latest   "/opt/bitnami/script…"   15 minutes ago   Up 15 minutes             sparkcluster_spark-worker.1.1pbt3ybrni8d72gq11a4k96hf
b6e91231c573   bitnami/spark:latest   "/opt/bitnami/script…"   55 minutes ago   Up 55 minutes             sparkcluster_spark-master.1.jt06h7e3t0eaxo52mqivmqang
masternod@master-node-VMware-Virtual-Platform:~$ docker exec -it b6e91231c573 bash
I have no name!@b6e91231c573:/opt/bitnami/spark$ cd /opt/bitnami/spark
I have no name!@b6e91231c573:/opt/bitnami/spark$ ls
LICENSE  R	    RELEASE  conf	   data      jars	 licenses  python  tmp	 work
NOTICE	 README.md  bin      conf.default  examples  kubernetes  logs	   sbin    venv  yarn
I have no name!@b6e91231c573:/opt/bitnami/spark$ ^C
I have no name!@b6e91231c573:/opt/bitnami/spark$ exit
exit
masternod@master-node-VMware-Virtual-Platform:~$ docker cp bio_classifier.py b6e91231c573:/opt/bitnami/spark/
Successfully copied 3.07kB to b6e91231c573:/opt/bitnami/spark/
masternod@master-node-VMware-Virtual-Platform:~$ docker cp cleaned_bio_dataset.csv b6e91231c573:/opt/bitnami/spark/
Successfully copied 13.3kB to b6e91231c573:/opt/bitnami/spark/
masternod@master-node-VMware-Virtual-Platform:~$ docker exec -it b6e91231c573 bash
I have no name!@b6e91231c573:/opt/bitnami/spark$ ls
LICENSE  R	    RELEASE  bio_classifier.py	      conf	    data      jars	  licenses  python  tmp   work
NOTICE	 README.md  bin      cleaned_bio_dataset.csv  conf.default  examples  kubernetes  logs	    sbin    venv  yarn
I have no name!@b6e91231c573:/opt/bitnami/spark$ spark-submit --master spark://spark-master:7077 bio_classifier.py
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:137)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1274)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1381)
	at org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:182)
	at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:339)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:969)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:199)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:222)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1125)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1134)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
I have no name!@b6e91231c573:/opt/bitnami/spark$ export HOME=/tmp
I have no name!@b6e91231c573:/opt/bitnami/spark$ spark-submit --master spark://spark-master:7077 bio_classifier.py
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:137)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1274)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1381)
	at org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:182)
	at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:339)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:969)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:199)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:222)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1125)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1134)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
I have no name!@b6e91231c573:/opt/bitnami/spark$ echo $HOME
/tmp
I have no name!@b6e91231c573:/opt/bitnami/spark$ mkdir -p $HOME/.ivy2
I have no name!@b6e91231c573:/opt/bitnami/spark$ export USER=root
I have no name!@b6e91231c573:/opt/bitnami/spark$ spark-submit --master spark://spark-master:7077 bio_classifier.py
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:137)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1274)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1381)
	at org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:182)
	at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:339)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:969)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:199)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:222)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1125)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1134)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
I have no name!@b6e91231c573:/opt/bitnami/spark$ env HOME=/tmp USER=root spark-submit --master spark://spark-master:7077 bio_classifier.py
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:137)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1274)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1381)
	at org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:182)
	at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:339)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:969)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:199)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:222)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1125)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1134)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
I have no name!@b6e91231c573:/opt/bitnami/spark$ exit
exit
masternod@master-node-VMware-Virtual-Platform:~$ docker exec -it --user root b6e91231c573 bash
root@b6e91231c573:/opt/bitnami/spark# export HOME=/tmp
root@b6e91231c573:/opt/bitnami/spark# export USER=root
root@b6e91231c573:/opt/bitnami/spark# mkdir -p $HOME/.ivy2
root@b6e91231c573:/opt/bitnami/spark# spark-submit --master spark://spark-master:7077 bio_classifier.py
25/06/02 19:01:33 INFO SparkContext: Running Spark version 3.5.6
25/06/02 19:01:33 INFO SparkContext: OS info Linux, 6.11.0-26-generic, amd64
25/06/02 19:01:33 INFO SparkContext: Java version 17.0.15
25/06/02 19:01:33 INFO ResourceUtils: ==============================================================
25/06/02 19:01:33 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/02 19:01:33 INFO ResourceUtils: ==============================================================
25/06/02 19:01:33 INFO SparkContext: Submitted application: BioClassifier
25/06/02 19:01:33 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/02 19:01:33 INFO ResourceProfile: Limiting resource is cpu
25/06/02 19:01:33 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/02 19:01:33 INFO SecurityManager: Changing view acls to: root,spark
25/06/02 19:01:33 INFO SecurityManager: Changing modify acls to: root,spark
25/06/02 19:01:33 INFO SecurityManager: Changing view acls groups to: 
25/06/02 19:01:33 INFO SecurityManager: Changing modify acls groups to: 
25/06/02 19:01:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
25/06/02 19:01:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/06/02 19:01:34 INFO Utils: Successfully started service 'sparkDriver' on port 40303.
25/06/02 19:01:34 INFO SparkEnv: Registering MapOutputTracker
25/06/02 19:01:34 INFO SparkEnv: Registering BlockManagerMaster
25/06/02 19:01:35 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/02 19:01:35 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/02 19:01:35 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/02 19:01:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d8800fba-ccf6-4c02-8430-1b0a1548254a
25/06/02 19:01:35 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
25/06/02 19:01:35 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/02 19:01:35 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/06/02 19:01:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/02 19:01:36 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/06/02 19:01:36 INFO TransportClientFactory: Successfully created connection to spark-master/10.0.2.2:7077 after 66 ms (0 ms spent in bootstraps)
25/06/02 19:01:36 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250602190136-0002
25/06/02 19:01:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37673.
25/06/02 19:01:36 INFO NettyBlockTransferService: Server created on b6e91231c573:37673
25/06/02 19:01:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/02 19:01:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250602190136-0002/0 on worker-20250531193237-10.0.2.10-43391 (10.0.2.10:43391) with 2 core(s)
25/06/02 19:01:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20250602190136-0002/0 on hostPort 10.0.2.10:43391 with 2 core(s), 1024.0 MiB RAM
25/06/02 19:01:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b6e91231c573, 37673, None)
25/06/02 19:01:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250602190136-0002/1 on worker-20250531193237-10.0.2.11-41307 (10.0.2.11:41307) with 2 core(s)
25/06/02 19:01:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20250602190136-0002/1 on hostPort 10.0.2.11:41307 with 2 core(s), 1024.0 MiB RAM
25/06/02 19:01:37 INFO BlockManagerMasterEndpoint: Registering block manager b6e91231c573:37673 with 434.4 MiB RAM, BlockManagerId(driver, b6e91231c573, 37673, None)
25/06/02 19:01:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b6e91231c573, 37673, None)
25/06/02 19:01:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b6e91231c573, 37673, None)
25/06/02 19:01:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250602190136-0002/1 is now RUNNING
25/06/02 19:01:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250602190136-0002/0 is now RUNNING
25/06/02 19:01:40 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/06/02 19:01:43 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/06/02 19:01:43 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/06/02 19:01:49 INFO InMemoryFileIndex: It took 347 ms to list leaf files for 1 paths.
25/06/02 19:01:50 INFO InMemoryFileIndex: It took 26 ms to list leaf files for 1 paths.
25/06/02 19:02:02 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.10:34504) with ID 0,  ResourceProfileId 0
25/06/02 19:02:02 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.11:50902) with ID 1,  ResourceProfileId 0
25/06/02 19:02:03 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.10:42919 with 434.4 MiB RAM, BlockManagerId(0, 10.0.2.10, 42919, None)
25/06/02 19:02:03 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.11:39821 with 434.4 MiB RAM, BlockManagerId(1, 10.0.2.11, 39821, None)
25/06/02 19:02:05 INFO FileSourceStrategy: Pushed Filters: 
25/06/02 19:02:05 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/06/02 19:02:06 INFO CodeGenerator: Code generated in 469.188674 ms
25/06/02 19:02:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.6 KiB, free 434.2 MiB)
25/06/02 19:02:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 434.2 MiB)
25/06/02 19:02:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b6e91231c573:37673 (size: 34.3 KiB, free: 434.4 MiB)
25/06/02 19:02:07 INFO SparkContext: Created broadcast 0 from csv at <unknown>:0
25/06/02 19:02:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/06/02 19:02:07 INFO SparkContext: Starting job: csv at <unknown>:0
25/06/02 19:02:07 INFO DAGScheduler: Got job 0 (csv at <unknown>:0) with 1 output partitions
25/06/02 19:02:07 INFO DAGScheduler: Final stage: ResultStage 0 (csv at <unknown>:0)
25/06/02 19:02:07 INFO DAGScheduler: Parents of final stage: List()
25/06/02 19:02:07 INFO DAGScheduler: Missing parents: List()
25/06/02 19:02:07 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0), which has no missing parents
25/06/02 19:02:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 434.2 MiB)
25/06/02 19:02:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.2 MiB)
25/06/02 19:02:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b6e91231c573:37673 (size: 6.4 KiB, free: 434.4 MiB)
25/06/02 19:02:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1611
25/06/02 19:02:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/06/02 19:02:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/06/02 19:02:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.0.2.10, executor 0, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:02:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.2.10:42919 (size: 6.4 KiB, free: 434.4 MiB)
25/06/02 19:02:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.10:42919 (size: 34.3 KiB, free: 434.4 MiB)
25/06/02 19:02:11 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (10.0.2.10 executor 0): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

25/06/02 19:02:11 INFO TaskSetManager: Starting task 0.1 in stage 0.0 (TID 1) (10.0.2.11, executor 1, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:02:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.2.11:39821 (size: 6.4 KiB, free: 434.4 MiB)
25/06/02 19:02:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.11:39821 (size: 34.3 KiB, free: 434.4 MiB)
25/06/02 19:02:15 INFO TaskSetManager: Lost task 0.1 in stage 0.0 (TID 1) on 10.0.2.11, executor 1: org.apache.spark.SparkFileNotFoundException (File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 1]
25/06/02 19:02:15 INFO TaskSetManager: Starting task 0.2 in stage 0.0 (TID 2) (10.0.2.10, executor 0, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:02:16 INFO TaskSetManager: Lost task 0.2 in stage 0.0 (TID 2) on 10.0.2.10, executor 0: org.apache.spark.SparkFileNotFoundException (File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 2]
25/06/02 19:02:16 INFO TaskSetManager: Starting task 0.3 in stage 0.0 (TID 3) (10.0.2.10, executor 0, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:02:16 INFO TaskSetManager: Lost task 0.3 in stage 0.0 (TID 3) on 10.0.2.10, executor 0: org.apache.spark.SparkFileNotFoundException (File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 3]
25/06/02 19:02:16 ERROR TaskSetManager: Task 0 in stage 0.0 failed 4 times; aborting job
25/06/02 19:02:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/06/02 19:02:16 INFO TaskSchedulerImpl: Cancelling stage 0
25/06/02 19:02:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.10 executor 0): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
25/06/02 19:02:16 INFO DAGScheduler: ResultStage 0 (csv at <unknown>:0) failed in 8.369 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.10 executor 0): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
25/06/02 19:02:16 INFO DAGScheduler: Job 0 failed: csv at <unknown>:0, took 8.591676 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/bio_classifier.py", line 10, in <module>
    df = spark.read.csv("cleaned_bio_dataset.csv", header=True, inferSchema=True)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 740, in csv
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o27.csv.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.10 executor 0): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2898)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2834)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2833)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2833)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1253)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1253)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1253)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3102)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3036)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3025)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:995)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4333)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3316)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3316)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3539)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.infer(CSVDataSource.scala:111)
	at org.apache.spark.sql.execution.datasources.csv.CSVDataSource.inferSchema(CSVDataSource.scala:64)
	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:62)
	at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)
	at scala.Option.orElse(Option.scala:447)
	at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:538)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.base/java.lang.reflect.Method.invoke(Unknown Source)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more

25/06/02 19:02:16 INFO SparkContext: Invoking stop() from shutdown hook
25/06/02 19:02:16 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/06/02 19:02:16 INFO SparkUI: Stopped Spark web UI at http://b6e91231c573:4040
25/06/02 19:02:17 INFO StandaloneSchedulerBackend: Shutting down all executors
25/06/02 19:02:17 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
25/06/02 19:02:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/02 19:02:17 INFO MemoryStore: MemoryStore cleared
25/06/02 19:02:17 INFO BlockManager: BlockManager stopped
25/06/02 19:02:17 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/02 19:02:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/02 19:02:17 INFO SparkContext: Successfully stopped SparkContext
25/06/02 19:02:17 INFO ShutdownHookManager: Shutdown hook called
25/06/02 19:02:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-c7c38766-9983-4d47-bd91-b40518673edd/pyspark-8611c028-3225-498a-a77d-0e7e9bf628f1
25/06/02 19:02:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-fe5e36f8-953a-4cef-a8ee-9e1479b93c8c
25/06/02 19:02:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-c7c38766-9983-4d47-bd91-b40518673edd
root@b6e91231c573:/opt/bitnami/spark# exit
exit
masternod@master-node-VMware-Virtual-Platform:~$ docker cp cleaned_bio_dataset.csv b6e91231c573:/opt/bitnami/spark/
Successfully copied 13.3kB to b6e91231c573:/opt/bitnami/spark/
masternod@master-node-VMware-Virtual-Platform:~$ docker exec -it --user root b6e91231c573 bash
root@b6e91231c573:/opt/bitnami/spark# cd /opt/bitnami/spark
root@b6e91231c573:/opt/bitnami/spark# ls
LICENSE  R	    RELEASE  bio_classifier.py	      conf	    data      jars	  licenses  python  tmp   work
NOTICE	 README.md  bin      cleaned_bio_dataset.csv  conf.default  examples  kubernetes  logs	    sbin    venv  yarn
root@b6e91231c573:/opt/bitnami/spark# spark-submit --master spark://spark-master:7077 bio_classifier.py
25/06/02 19:05:45 INFO SparkContext: Running Spark version 3.5.6
25/06/02 19:05:45 INFO SparkContext: OS info Linux, 6.11.0-26-generic, amd64
25/06/02 19:05:45 INFO SparkContext: Java version 17.0.15
25/06/02 19:05:45 INFO ResourceUtils: ==============================================================
25/06/02 19:05:45 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/02 19:05:45 INFO ResourceUtils: ==============================================================
25/06/02 19:05:45 INFO SparkContext: Submitted application: BioClassifier
25/06/02 19:05:46 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/02 19:05:46 INFO ResourceProfile: Limiting resource is cpu
25/06/02 19:05:46 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/02 19:05:46 INFO SecurityManager: Changing view acls to: root,spark
25/06/02 19:05:46 INFO SecurityManager: Changing modify acls to: root,spark
25/06/02 19:05:46 INFO SecurityManager: Changing view acls groups to: 
25/06/02 19:05:46 INFO SecurityManager: Changing modify acls groups to: 
25/06/02 19:05:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
25/06/02 19:05:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/06/02 19:05:47 INFO Utils: Successfully started service 'sparkDriver' on port 38703.
25/06/02 19:05:47 INFO SparkEnv: Registering MapOutputTracker
25/06/02 19:05:47 INFO SparkEnv: Registering BlockManagerMaster
25/06/02 19:05:47 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/02 19:05:47 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/02 19:05:47 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/02 19:05:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d1d48a83-c289-4517-a192-e7da95851513
25/06/02 19:05:47 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
25/06/02 19:05:47 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/02 19:05:48 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/06/02 19:05:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/02 19:05:48 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/06/02 19:05:48 INFO TransportClientFactory: Successfully created connection to spark-master/10.0.2.2:7077 after 127 ms (0 ms spent in bootstraps)
25/06/02 19:05:49 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250602190548-0003
25/06/02 19:05:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250602190548-0003/0 on worker-20250531193237-10.0.2.10-43391 (10.0.2.10:43391) with 2 core(s)
25/06/02 19:05:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250602190548-0003/0 on hostPort 10.0.2.10:43391 with 2 core(s), 1024.0 MiB RAM
25/06/02 19:05:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250602190548-0003/1 on worker-20250531193237-10.0.2.11-41307 (10.0.2.11:41307) with 2 core(s)
25/06/02 19:05:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250602190548-0003/1 on hostPort 10.0.2.11:41307 with 2 core(s), 1024.0 MiB RAM
25/06/02 19:05:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46719.
25/06/02 19:05:49 INFO NettyBlockTransferService: Server created on b6e91231c573:46719
25/06/02 19:05:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/02 19:05:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b6e91231c573, 46719, None)
25/06/02 19:05:49 INFO BlockManagerMasterEndpoint: Registering block manager b6e91231c573:46719 with 434.4 MiB RAM, BlockManagerId(driver, b6e91231c573, 46719, None)
25/06/02 19:05:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b6e91231c573, 46719, None)
25/06/02 19:05:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b6e91231c573, 46719, None)
25/06/02 19:05:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250602190548-0003/1 is now RUNNING
25/06/02 19:05:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250602190548-0003/0 is now RUNNING
25/06/02 19:05:50 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/06/02 19:05:53 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/06/02 19:05:53 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/06/02 19:05:57 INFO InMemoryFileIndex: It took 185 ms to list leaf files for 1 paths.
25/06/02 19:05:58 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.
25/06/02 19:06:05 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.10:44524) with ID 0,  ResourceProfileId 0
25/06/02 19:06:06 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.10:40213 with 434.4 MiB RAM, BlockManagerId(0, 10.0.2.10, 40213, None)
25/06/02 19:06:06 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.11:43034) with ID 1,  ResourceProfileId 0
25/06/02 19:06:07 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.11:45597 with 434.4 MiB RAM, BlockManagerId(1, 10.0.2.11, 45597, None)
25/06/02 19:06:08 INFO FileSourceStrategy: Pushed Filters: 
25/06/02 19:06:08 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/06/02 19:06:09 INFO CodeGenerator: Code generated in 526.847415 ms
25/06/02 19:06:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.6 KiB, free 434.2 MiB)
25/06/02 19:06:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 434.2 MiB)
25/06/02 19:06:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b6e91231c573:46719 (size: 34.3 KiB, free: 434.4 MiB)
25/06/02 19:06:09 INFO SparkContext: Created broadcast 0 from csv at <unknown>:0
25/06/02 19:06:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/06/02 19:06:09 INFO SparkContext: Starting job: csv at <unknown>:0
25/06/02 19:06:09 INFO DAGScheduler: Got job 0 (csv at <unknown>:0) with 1 output partitions
25/06/02 19:06:09 INFO DAGScheduler: Final stage: ResultStage 0 (csv at <unknown>:0)
25/06/02 19:06:09 INFO DAGScheduler: Parents of final stage: List()
25/06/02 19:06:09 INFO DAGScheduler: Missing parents: List()
25/06/02 19:06:09 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0), which has no missing parents
25/06/02 19:06:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 434.2 MiB)
25/06/02 19:06:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.2 MiB)
25/06/02 19:06:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b6e91231c573:46719 (size: 6.4 KiB, free: 434.4 MiB)
25/06/02 19:06:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1611
25/06/02 19:06:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/06/02 19:06:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/06/02 19:06:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.0.2.10, executor 0, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:06:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.2.10:40213 (size: 6.4 KiB, free: 434.4 MiB)
25/06/02 19:06:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.10:40213 (size: 34.3 KiB, free: 434.4 MiB)
25/06/02 19:06:13 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (10.0.2.10 executor 0): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

25/06/02 19:06:13 INFO TaskSetManager: Starting task 0.1 in stage 0.0 (TID 1) (10.0.2.10, executor 0, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:06:13 INFO TaskSetManager: Lost task 0.1 in stage 0.0 (TID 1) on 10.0.2.10, executor 0: org.apache.spark.SparkFileNotFoundException (File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 1]
25/06/02 19:06:13 INFO TaskSetManager: Starting task 0.2 in stage 0.0 (TID 2) (10.0.2.10, executor 0, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:06:13 INFO TaskSetManager: Lost task 0.2 in stage 0.0 (TID 2) on 10.0.2.10, executor 0: org.apache.spark.SparkFileNotFoundException (File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 2]
25/06/02 19:06:13 INFO TaskSetManager: Starting task 0.3 in stage 0.0 (TID 3) (10.0.2.10, executor 0, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:06:13 INFO TaskSetManager: Lost task 0.3 in stage 0.0 (TID 3) on 10.0.2.10, executor 0: org.apache.spark.SparkFileNotFoundException (File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 3]
25/06/02 19:06:13 ERROR TaskSetManager: Task 0 in stage 0.0 failed 4 times; aborting job
25/06/02 19:06:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/06/02 19:06:13 INFO TaskSchedulerImpl: Cancelling stage 0
25/06/02 19:06:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.10 executor 0): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
25/06/02 19:06:13 INFO DAGScheduler: ResultStage 0 (csv at <unknown>:0) failed in 3.978 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.10 executor 0): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
25/06/02 19:06:14 INFO DAGScheduler: Job 0 failed: csv at <unknown>:0, took 4.201304 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/bio_classifier.py", line 10, in <module>
    df = spark.read.csv("cleaned_bio_dataset.csv", header=True, inferSchema=True)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 740, in csv
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o27.csv.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.10 executor 0): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2898)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2834)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2833)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2833)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1253)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1253)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1253)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3102)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3036)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3025)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:995)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4333)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3316)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3316)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3539)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.infer(CSVDataSource.scala:111)
	at org.apache.spark.sql.execution.datasources.csv.CSVDataSource.inferSchema(CSVDataSource.scala:64)
	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:62)
	at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)
	at scala.Option.orElse(Option.scala:447)
	at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:538)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.base/java.lang.reflect.Method.invoke(Unknown Source)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more

25/06/02 19:06:14 INFO SparkContext: Invoking stop() from shutdown hook
25/06/02 19:06:14 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/06/02 19:06:14 INFO SparkUI: Stopped Spark web UI at http://b6e91231c573:4040
25/06/02 19:06:14 INFO StandaloneSchedulerBackend: Shutting down all executors
25/06/02 19:06:14 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
25/06/02 19:06:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/02 19:06:15 INFO MemoryStore: MemoryStore cleared
25/06/02 19:06:15 INFO BlockManager: BlockManager stopped
25/06/02 19:06:15 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/02 19:06:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/02 19:06:15 INFO SparkContext: Successfully stopped SparkContext
25/06/02 19:06:15 INFO ShutdownHookManager: Shutdown hook called
25/06/02 19:06:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-74b8a119-a26c-4735-a93f-7919d3cefb89
25/06/02 19:06:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-47c79cab-5c1f-4ff1-bd2c-7884cb820f7a/pyspark-f8d8c550-e9a0-46d5-8a1c-660eb7e2f263
25/06/02 19:06:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-47c79cab-5c1f-4ff1-bd2c-7884cb820f7a
root@b6e91231c573:/opt/bitnami/spark# exit
exit
masternod@master-node-VMware-Virtual-Platform:~$ docker exec -it b6e91231c573 ls /opt/bitnami/spark
LICENSE  R	    RELEASE  bio_classifier.py	      conf	    data      jars	  licenses  python  tmp   work
NOTICE	 README.md  bin      cleaned_bio_dataset.csv  conf.default  examples  kubernetes  logs	    sbin    venv  yarn
masternod@master-node-VMware-Virtual-Platform:~$ docker exec -it b6e91231c573 bash
I have no name!@b6e91231c573:/opt/bitnami/spark$ exit
exit
masternod@master-node-VMware-Virtual-Platform:~$ docker exec -it --user root b6e91231c573 bash
root@b6e91231c573:/opt/bitnami/spark# ls -l /opt/bitnami/spark/cleaned_bio_dataset.csv
-rw-rw-r-- 1 1000 1000 11753 May 30 14:14 /opt/bitnami/spark/cleaned_bio_dataset.csv
root@b6e91231c573:/opt/bitnami/spark# spark-submit --master spark://spark-master:7077 bio_classifier.py
25/06/02 19:12:15 INFO SparkContext: Running Spark version 3.5.6
25/06/02 19:12:15 INFO SparkContext: OS info Linux, 6.11.0-26-generic, amd64
25/06/02 19:12:15 INFO SparkContext: Java version 17.0.15
25/06/02 19:12:16 INFO ResourceUtils: ==============================================================
25/06/02 19:12:16 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/02 19:12:16 INFO ResourceUtils: ==============================================================
25/06/02 19:12:16 INFO SparkContext: Submitted application: BioClassifier
25/06/02 19:12:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/02 19:12:16 INFO ResourceProfile: Limiting resource is cpu
25/06/02 19:12:16 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/02 19:12:16 INFO SecurityManager: Changing view acls to: root,spark
25/06/02 19:12:16 INFO SecurityManager: Changing modify acls to: root,spark
25/06/02 19:12:16 INFO SecurityManager: Changing view acls groups to: 
25/06/02 19:12:16 INFO SecurityManager: Changing modify acls groups to: 
25/06/02 19:12:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
25/06/02 19:12:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/06/02 19:12:16 INFO Utils: Successfully started service 'sparkDriver' on port 45075.
25/06/02 19:12:17 INFO SparkEnv: Registering MapOutputTracker
25/06/02 19:12:17 INFO SparkEnv: Registering BlockManagerMaster
25/06/02 19:12:17 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/02 19:12:17 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/02 19:12:17 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/02 19:12:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9f6aabb5-5978-4fde-a8d7-a2ba2834851d
25/06/02 19:12:17 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
25/06/02 19:12:17 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/02 19:12:17 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/06/02 19:12:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/02 19:12:18 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/06/02 19:12:18 INFO TransportClientFactory: Successfully created connection to spark-master/10.0.2.2:7077 after 57 ms (0 ms spent in bootstraps)
25/06/02 19:12:18 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250602191218-0004
25/06/02 19:12:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250602191218-0004/0 on worker-20250531193237-10.0.2.10-43391 (10.0.2.10:43391) with 2 core(s)
25/06/02 19:12:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20250602191218-0004/0 on hostPort 10.0.2.10:43391 with 2 core(s), 1024.0 MiB RAM
25/06/02 19:12:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250602191218-0004/1 on worker-20250531193237-10.0.2.11-41307 (10.0.2.11:41307) with 2 core(s)
25/06/02 19:12:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20250602191218-0004/1 on hostPort 10.0.2.11:41307 with 2 core(s), 1024.0 MiB RAM
25/06/02 19:12:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32777.
25/06/02 19:12:18 INFO NettyBlockTransferService: Server created on b6e91231c573:32777
25/06/02 19:12:18 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/02 19:12:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b6e91231c573, 32777, None)
25/06/02 19:12:18 INFO BlockManagerMasterEndpoint: Registering block manager b6e91231c573:32777 with 434.4 MiB RAM, BlockManagerId(driver, b6e91231c573, 32777, None)
25/06/02 19:12:18 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b6e91231c573, 32777, None)
25/06/02 19:12:18 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b6e91231c573, 32777, None)
25/06/02 19:12:19 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250602191218-0004/0 is now RUNNING
25/06/02 19:12:19 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250602191218-0004/1 is now RUNNING
25/06/02 19:12:20 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/06/02 19:12:21 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/06/02 19:12:22 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/06/02 19:12:26 INFO InMemoryFileIndex: It took 312 ms to list leaf files for 1 paths.
25/06/02 19:12:27 INFO InMemoryFileIndex: It took 10 ms to list leaf files for 1 paths.
25/06/02 19:12:36 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.11:60222) with ID 1,  ResourceProfileId 0
25/06/02 19:12:36 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.10:42424) with ID 0,  ResourceProfileId 0
25/06/02 19:12:37 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.11:37743 with 434.4 MiB RAM, BlockManagerId(1, 10.0.2.11, 37743, None)
25/06/02 19:12:37 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.10:37927 with 434.4 MiB RAM, BlockManagerId(0, 10.0.2.10, 37927, None)
25/06/02 19:12:38 INFO FileSourceStrategy: Pushed Filters: 
25/06/02 19:12:38 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/06/02 19:12:39 INFO CodeGenerator: Code generated in 697.594842 ms
25/06/02 19:12:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.6 KiB, free 434.2 MiB)
25/06/02 19:12:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 434.2 MiB)
25/06/02 19:12:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b6e91231c573:32777 (size: 34.3 KiB, free: 434.4 MiB)
25/06/02 19:12:39 INFO SparkContext: Created broadcast 0 from csv at <unknown>:0
25/06/02 19:12:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/06/02 19:12:39 INFO SparkContext: Starting job: csv at <unknown>:0
25/06/02 19:12:40 INFO DAGScheduler: Got job 0 (csv at <unknown>:0) with 1 output partitions
25/06/02 19:12:40 INFO DAGScheduler: Final stage: ResultStage 0 (csv at <unknown>:0)
25/06/02 19:12:40 INFO DAGScheduler: Parents of final stage: List()
25/06/02 19:12:40 INFO DAGScheduler: Missing parents: List()
25/06/02 19:12:40 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0), which has no missing parents
25/06/02 19:12:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 434.2 MiB)
25/06/02 19:12:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.2 MiB)
25/06/02 19:12:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b6e91231c573:32777 (size: 6.4 KiB, free: 434.4 MiB)
25/06/02 19:12:40 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1611
25/06/02 19:12:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/06/02 19:12:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/06/02 19:12:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.0.2.10, executor 0, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:12:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.2.10:37927 (size: 6.4 KiB, free: 434.4 MiB)
25/06/02 19:12:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.10:37927 (size: 34.3 KiB, free: 434.4 MiB)
25/06/02 19:12:43 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (10.0.2.10 executor 0): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

25/06/02 19:12:44 INFO TaskSetManager: Starting task 0.1 in stage 0.0 (TID 1) (10.0.2.10, executor 0, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:12:44 INFO TaskSetManager: Lost task 0.1 in stage 0.0 (TID 1) on 10.0.2.10, executor 0: org.apache.spark.SparkFileNotFoundException (File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 1]
25/06/02 19:12:44 INFO TaskSetManager: Starting task 0.2 in stage 0.0 (TID 2) (10.0.2.10, executor 0, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:12:44 INFO TaskSetManager: Lost task 0.2 in stage 0.0 (TID 2) on 10.0.2.10, executor 0: org.apache.spark.SparkFileNotFoundException (File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 2]
25/06/02 19:12:44 INFO TaskSetManager: Starting task 0.3 in stage 0.0 (TID 3) (10.0.2.11, executor 1, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:12:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.2.11:37743 (size: 6.4 KiB, free: 434.4 MiB)
25/06/02 19:12:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.11:37743 (size: 34.3 KiB, free: 434.4 MiB)
25/06/02 19:12:48 INFO TaskSetManager: Lost task 0.3 in stage 0.0 (TID 3) on 10.0.2.11, executor 1: org.apache.spark.SparkFileNotFoundException (File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 3]
25/06/02 19:12:48 ERROR TaskSetManager: Task 0 in stage 0.0 failed 4 times; aborting job
25/06/02 19:12:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/06/02 19:12:48 INFO TaskSchedulerImpl: Cancelling stage 0
25/06/02 19:12:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.11 executor 1): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
25/06/02 19:12:48 INFO DAGScheduler: ResultStage 0 (csv at <unknown>:0) failed in 8.228 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.11 executor 1): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
25/06/02 19:12:48 INFO DAGScheduler: Job 0 failed: csv at <unknown>:0, took 8.387492 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/bio_classifier.py", line 10, in <module>
    df = spark.read.csv("cleaned_bio_dataset.csv", header=True, inferSchema=True)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 740, in csv
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o27.csv.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.11 executor 1): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2898)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2834)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2833)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2833)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1253)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1253)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1253)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3102)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3036)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3025)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:995)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4333)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3316)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3316)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3539)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.infer(CSVDataSource.scala:111)
	at org.apache.spark.sql.execution.datasources.csv.CSVDataSource.inferSchema(CSVDataSource.scala:64)
	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:62)
	at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)
	at scala.Option.orElse(Option.scala:447)
	at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:538)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.base/java.lang.reflect.Method.invoke(Unknown Source)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more

25/06/02 19:12:49 INFO SparkContext: Invoking stop() from shutdown hook
25/06/02 19:12:49 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/06/02 19:12:49 INFO SparkUI: Stopped Spark web UI at http://b6e91231c573:4040
25/06/02 19:12:49 INFO StandaloneSchedulerBackend: Shutting down all executors
25/06/02 19:12:49 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
25/06/02 19:12:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/02 19:12:49 INFO MemoryStore: MemoryStore cleared
25/06/02 19:12:49 INFO BlockManager: BlockManager stopped
25/06/02 19:12:49 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/02 19:12:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/02 19:12:49 INFO SparkContext: Successfully stopped SparkContext
25/06/02 19:12:49 INFO ShutdownHookManager: Shutdown hook called
25/06/02 19:12:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-3c62b135-ab06-4f77-a5ef-292f469e9026/pyspark-4365e36a-f427-46e8-9e1e-9be31b76caf9
25/06/02 19:12:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-3c62b135-ab06-4f77-a5ef-292f469e9026
25/06/02 19:12:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-64531068-dece-4691-b322-1470daafcf6d
root@b6e91231c573:/opt/bitnami/spark# ls -l /opt/bitnami/spark/result.txt
ls: cannot access '/opt/bitnami/spark/result.txt': No such file or directory
root@b6e91231c573:/opt/bitnami/spark# python3 bio_classifier.py
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/06/02 19:17:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/06/02 19:17:29 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS
25/06/02 19:17:29 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS

✅ Model Accuracy: 100.00%

root@b6e91231c573:/opt/bitnami/spark# exit
exit
masternod@master-node-VMware-Virtual-Platform:~$ nano bio_classifier.py
masternod@master-node-VMware-Virtual-Platform:~$ docker cp bio_classifier.py b6e91231c573:/opt/bitnami/spark/
Successfully copied 3.58kB to b6e91231c573:/opt/bitnami/spark/
masternod@master-node-VMware-Virtual-Platform:~$ docker exec -it --user root b6e91231c573 bash
root@b6e91231c573:/opt/bitnami/spark# ls -l /opt/bitnami/spark/cleaned_bio_dataset.csv
-rw-rw-r-- 1 1000 1000 11753 May 30 14:14 /opt/bitnami/spark/cleaned_bio_dataset.csv
root@b6e91231c573:/opt/bitnami/spark# ls
LICENSE  README.md  bio_classifier.py	     conf.default  jars        logs	   sbin  work
NOTICE	 RELEASE    cleaned_bio_dataset.csv  data	   kubernetes  python	   tmp	 yarn
R	 bin	    conf		     examples	   licenses    result.txt  venv
root@b6e91231c573:/opt/bitnami/spark# spark-submit --master spark://spark-master:7077 bio_classifier.py
25/06/02 19:24:55 INFO SparkContext: Running Spark version 3.5.6
25/06/02 19:24:55 INFO SparkContext: OS info Linux, 6.11.0-26-generic, amd64
25/06/02 19:24:55 INFO SparkContext: Java version 17.0.15
25/06/02 19:24:55 INFO ResourceUtils: ==============================================================
25/06/02 19:24:55 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/02 19:24:55 INFO ResourceUtils: ==============================================================
25/06/02 19:24:55 INFO SparkContext: Submitted application: BioClassifier
25/06/02 19:24:55 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/02 19:24:55 INFO ResourceProfile: Limiting resource is cpu
25/06/02 19:24:55 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/02 19:24:55 INFO SecurityManager: Changing view acls to: root,spark
25/06/02 19:24:55 INFO SecurityManager: Changing modify acls to: root,spark
25/06/02 19:24:55 INFO SecurityManager: Changing view acls groups to: 
25/06/02 19:24:55 INFO SecurityManager: Changing modify acls groups to: 
25/06/02 19:24:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
25/06/02 19:24:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/06/02 19:24:56 INFO Utils: Successfully started service 'sparkDriver' on port 37567.
25/06/02 19:24:56 INFO SparkEnv: Registering MapOutputTracker
25/06/02 19:24:56 INFO SparkEnv: Registering BlockManagerMaster
25/06/02 19:24:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/02 19:24:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/02 19:24:56 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/02 19:24:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3731f392-291d-4399-ab2a-628e042df3bb
25/06/02 19:24:56 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
25/06/02 19:24:56 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/02 19:24:56 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/06/02 19:24:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/02 19:24:57 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/06/02 19:24:57 INFO TransportClientFactory: Successfully created connection to spark-master/10.0.2.2:7077 after 72 ms (0 ms spent in bootstraps)
25/06/02 19:24:57 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250602192457-0005
25/06/02 19:24:57 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250602192457-0005/0 on worker-20250531193237-10.0.2.10-43391 (10.0.2.10:43391) with 2 core(s)
25/06/02 19:24:57 INFO StandaloneSchedulerBackend: Granted executor ID app-20250602192457-0005/0 on hostPort 10.0.2.10:43391 with 2 core(s), 1024.0 MiB RAM
25/06/02 19:24:57 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250602192457-0005/1 on worker-20250531193237-10.0.2.11-41307 (10.0.2.11:41307) with 2 core(s)
25/06/02 19:24:57 INFO StandaloneSchedulerBackend: Granted executor ID app-20250602192457-0005/1 on hostPort 10.0.2.11:41307 with 2 core(s), 1024.0 MiB RAM
25/06/02 19:24:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45283.
25/06/02 19:24:57 INFO NettyBlockTransferService: Server created on b6e91231c573:45283
25/06/02 19:24:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/02 19:24:58 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250602192457-0005/0 is now RUNNING
25/06/02 19:24:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b6e91231c573, 45283, None)
25/06/02 19:24:58 INFO BlockManagerMasterEndpoint: Registering block manager b6e91231c573:45283 with 434.4 MiB RAM, BlockManagerId(driver, b6e91231c573, 45283, None)
25/06/02 19:24:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b6e91231c573, 45283, None)
25/06/02 19:24:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b6e91231c573, 45283, None)
25/06/02 19:24:58 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250602192457-0005/1 is now RUNNING
25/06/02 19:24:59 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/06/02 19:25:01 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/06/02 19:25:01 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/06/02 19:25:07 INFO InMemoryFileIndex: It took 1134 ms to list leaf files for 1 paths.
25/06/02 19:25:07 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.
25/06/02 19:25:18 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.11:39088) with ID 1,  ResourceProfileId 0
25/06/02 19:25:19 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.11:38789 with 434.4 MiB RAM, BlockManagerId(1, 10.0.2.11, 38789, None)
25/06/02 19:25:19 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.10:45168) with ID 0,  ResourceProfileId 0
25/06/02 19:25:19 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.10:41407 with 434.4 MiB RAM, BlockManagerId(0, 10.0.2.10, 41407, None)
25/06/02 19:25:20 INFO FileSourceStrategy: Pushed Filters: 
25/06/02 19:25:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/06/02 19:25:21 INFO CodeGenerator: Code generated in 364.141556 ms
25/06/02 19:25:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.6 KiB, free 434.2 MiB)
25/06/02 19:25:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 434.2 MiB)
25/06/02 19:25:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b6e91231c573:45283 (size: 34.3 KiB, free: 434.4 MiB)
25/06/02 19:25:21 INFO SparkContext: Created broadcast 0 from csv at <unknown>:0
25/06/02 19:25:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/06/02 19:25:22 INFO SparkContext: Starting job: csv at <unknown>:0
25/06/02 19:25:22 INFO DAGScheduler: Got job 0 (csv at <unknown>:0) with 1 output partitions
25/06/02 19:25:22 INFO DAGScheduler: Final stage: ResultStage 0 (csv at <unknown>:0)
25/06/02 19:25:22 INFO DAGScheduler: Parents of final stage: List()
25/06/02 19:25:22 INFO DAGScheduler: Missing parents: List()
25/06/02 19:25:22 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0), which has no missing parents
25/06/02 19:25:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 434.2 MiB)
25/06/02 19:25:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.2 MiB)
25/06/02 19:25:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b6e91231c573:45283 (size: 6.4 KiB, free: 434.4 MiB)
25/06/02 19:25:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1611
25/06/02 19:25:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/06/02 19:25:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/06/02 19:25:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.0.2.11, executor 1, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:25:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.2.11:38789 (size: 6.4 KiB, free: 434.4 MiB)
25/06/02 19:25:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.11:38789 (size: 34.3 KiB, free: 434.4 MiB)
25/06/02 19:25:26 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (10.0.2.11 executor 1): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

25/06/02 19:25:26 INFO TaskSetManager: Starting task 0.1 in stage 0.0 (TID 1) (10.0.2.11, executor 1, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:25:26 INFO TaskSetManager: Lost task 0.1 in stage 0.0 (TID 1) on 10.0.2.11, executor 1: org.apache.spark.SparkFileNotFoundException (File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 1]
25/06/02 19:25:26 INFO TaskSetManager: Starting task 0.2 in stage 0.0 (TID 2) (10.0.2.11, executor 1, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:25:26 INFO TaskSetManager: Lost task 0.2 in stage 0.0 (TID 2) on 10.0.2.11, executor 1: org.apache.spark.SparkFileNotFoundException (File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 2]
25/06/02 19:25:26 INFO TaskSetManager: Starting task 0.3 in stage 0.0 (TID 3) (10.0.2.11, executor 1, partition 0, PROCESS_LOCAL, 9615 bytes) 
25/06/02 19:25:26 INFO TaskSetManager: Lost task 0.3 in stage 0.0 (TID 3) on 10.0.2.11, executor 1: org.apache.spark.SparkFileNotFoundException (File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.) [duplicate 3]
25/06/02 19:25:26 ERROR TaskSetManager: Task 0 in stage 0.0 failed 4 times; aborting job
25/06/02 19:25:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/06/02 19:25:26 INFO TaskSchedulerImpl: Cancelling stage 0
25/06/02 19:25:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.11 executor 1): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
25/06/02 19:25:27 INFO DAGScheduler: ResultStage 0 (csv at <unknown>:0) failed in 4.576 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.11 executor 1): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
25/06/02 19:25:27 INFO DAGScheduler: Job 0 failed: csv at <unknown>:0, took 4.806796 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/bio_classifier.py", line 10, in <module>
    df = spark.read.csv("cleaned_bio_dataset.csv", header=True, inferSchema=True)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 740, in csv
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o27.csv.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (10.0.2.11 executor 1): org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2898)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2834)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2833)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2833)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1253)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1253)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1253)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3102)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3036)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3025)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:995)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4333)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3316)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3316)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3539)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.infer(CSVDataSource.scala:111)
	at org.apache.spark.sql.execution.datasources.csv.CSVDataSource.inferSchema(CSVDataSource.scala:64)
	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:62)
	at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)
	at scala.Option.orElse(Option.scala:447)
	at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:538)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.base/java.lang.reflect.Method.invoke(Unknown Source)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkFileNotFoundException: File file:/opt/bitnami/spark/cleaned_bio_dataset.csv does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more

25/06/02 19:25:27 INFO SparkContext: Invoking stop() from shutdown hook
25/06/02 19:25:27 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/06/02 19:25:27 INFO SparkUI: Stopped Spark web UI at http://b6e91231c573:4040
25/06/02 19:25:27 INFO StandaloneSchedulerBackend: Shutting down all executors
25/06/02 19:25:27 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
25/06/02 19:25:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/02 19:25:28 INFO MemoryStore: MemoryStore cleared
25/06/02 19:25:28 INFO BlockManager: BlockManager stopped
25/06/02 19:25:28 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/02 19:25:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/02 19:25:28 INFO SparkContext: Successfully stopped SparkContext
25/06/02 19:25:28 INFO ShutdownHookManager: Shutdown hook called
25/06/02 19:25:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-52b61f5d-1367-4ee4-ae0d-bce8459f6a03
25/06/02 19:25:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-e8edec0f-714b-4b33-92e7-cca1db4951de
25/06/02 19:25:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-52b61f5d-1367-4ee4-ae0d-bce8459f6a03/pyspark-18bd2d5c-e7a3-41c7-882b-65553e63e4c4
root@b6e91231c573:/opt/bitnami/spark# docker cp b6e91231c573:/opt/bitnami/spark/result.txt ./
bash: docker: command not found
root@b6e91231c573:/opt/bitnami/spark# exit                                                   
exit
masternod@master-node-VMware-Virtual-Platform:~$ docker cp b6e91231c573:/opt/bitnami/spark/result.txt ./
Successfully copied 2.05kB to /home/masternod/./
masternod@master-node-VMware-Virtual-Platform:~$ cat result.txt
Model Accuracy: 100.00%
masternod@master-node-VMware-Virtual-Platform:~$ 


